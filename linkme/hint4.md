# 課題４（irisのデータ分析）のヒント


## irisのデータをどう扱うの？
まず，この`iris`のデータを詳しくみてみる必要がある．そこで，データを確認するためのPythonライブラリで`seaborn`，`pandas`，`matplotlib`などがあるので，まずは，`iris`のデータについて分析してみましょう．

まず初めに`iris`のデータを可視化してみます．

### コード

```python
import seaborn as sns
from matplotlib import pyplot as plt

sns.set()

print(iris)
```



### 実行結果

```
     sepal_length  sepal_width  petal_length  petal_width    species
0             5.1          3.5           1.4          0.2     setosa
1             4.9          3.0           1.4          0.2     setosa
2             4.7          3.2           1.3          0.2     setosa
3             4.6          3.1           1.5          0.2     setosa
4             5.0          3.6           1.4          0.2     setosa
..            ...          ...           ...          ...        ...
145           6.7          3.0           5.2          2.3  virginica
146           6.3          2.5           5.0          1.9  virginica
147           6.5          3.0           5.2          2.0  virginica
148           6.2          3.4           5.4          2.3  virginica
149           5.9          3.0           5.1          1.8  virginica
```

このデータの中身はこの結果の通りです．縦軸がデータの試料数，横軸は各項目の通りになっています．

`sepal_length`はがく片の長さ，`sepal_width`はがく片の幅，`petal_length`は花弁の長さ，`petal_width`は花弁の幅，`species`は種（`setosa`，`versicolor`，`virginica`）の要素になっている．

このデータをグラフにプロット（描画）してみる．グラフにはいろいろある．

### 散布図

```python
#これでグラフにプロットできる
sns.pairplot(iris)
plt.show()
plt.close()

```

`sns.pairplot(iris)`の部分で，`iris`のデータセットをプロットするための関数に送ってグラフをプロットしてくれる．

実行結果は以下のようになっているはず．

![image1](https://i.imgur.com/u40CFS5.png)  




```python
#これでグラフにプロットできる
sns.pairplot(iris, hue="species")
plt.show()
plt.close()

```

`sns.pairplot(iris, hue="species")`の部分で，`pairplot`関数の引数にデータセットと`hue="species"`を指定すると，`species`の種類で色分けしてくれる．



この要素の関係性を見ていくのがデータ分析である．



## データ分析入門

このデータを見て，何かわかったことがあるだろう．高校数学の中でデータの分析や統計的な確率といった単元があるだろう．その中の知識のみでこのデータを分析することができる．

まずは，ここまでのプログラムを整理していく．

```python
# 課題４irisのデータ分析

import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt

#seabornの機能を使えるようにする
sns.set()

#irisのデータをダウンロードする
iris = sns.load_dataset("iris")

# irisのデータ情報を表示する
print(iris)

#これでグラフにプロットできる
sns.pairplot(iris,hue="species")
plt.show()
plt.close()

```

![image01](https://i.imgur.com/I4eBB40.png)  

このデータをパッとみると，`setosa`だけ，特徴的なグラフをしていることがわかる．他の2つはなんだか似たような傾向がありそうである．


このデータを見たときに，いくつかの分析ポイントがある．今回はその簡単な例を挙げる．

### データ分析のポイント

- 代表値の確認
- 相関の確認
- 線形分析（発展）
- 非線形分析（発展）

この辺をみるデータの基本的な特徴を見ることができるだろう．

では早速分析を始める．

#### 代表値の確認

簡単に代表値を確認するには，`iris.describe()`を実行する．

コード

```python
# irisの代表値の確認
print(iris.describe())
```

これを追加して実行すれば，

```
       sepal_length  sepal_width  petal_length  petal_width
count    150.000000   150.000000    150.000000   150.000000
mean       5.843333     3.057333      3.758000     1.199333
std        0.828066     0.435866      1.765298     0.762238
min        4.300000     2.000000      1.000000     0.100000
25%        5.100000     2.800000      1.600000     0.300000
50%        5.800000     3.000000      4.350000     1.300000
75%        6.400000     3.300000      5.100000     1.800000
max        7.900000     4.400000      6.900000     2.500000
```

このように，実行される．各データ項目に対して，代表値を算出してくれる．なお，この代表値は以下のようになっている．

|カラム名|意味|補足|
|---|---|---|
|count|レコード数|データの数|
|mean|平均|データの和をレコード数で割ったもの|
|std|標準偏差|データの散らばり度合い|
|min|最小値|データの最小の値|
|25%|25%パーセンタイル|第一四分位数|
|50%|50%パーセンタイル|第二四分位数（中央値）|
|75%|75%パーセンタイル|第三四分位数|
|max|最大値|最大の値|

これに加えて統計の世界の深みに入っていくので，以下のサイトを先に見てからこの章を進めていくとかなり効率の良い学習ができることだろう．

[標準偏差とは？初学者向けに意味から求め方までわかりやすく解説](https://data-viz-lab.com/standarddeviation)  

データごとに`describe`することもできる．

```python
print(iris["sepal_length"].describe())
```


```
count    150.000000
mean       5.843333
std        0.828066
min        4.300000
25%        5.100000
50%        5.800000
75%        6.400000
max        7.900000
Name: sepal_length, dtype: float64
```

注意）ただ闇雲にデータを片っ端から分析しても効率が悪い．慣れてくると，ある程度予想をして関係のありそうなところを優先的に分析していくと効率も良いし，自分にとっての良い学習になるだろう．


#### 相関

見た感じ相関があるないは判断できるが計算したらどうなるだろうか．相関を計算するには，`iris.corr()`を使う．今回はこれを`heatmap`にして，可視化しつつ計算を行うこととする．


```
# snsの中にあるheatmap関数に相関係数と最大値最小値を与えてannotで相関係数を表示するかどうかを決める．
# なお，heatmapは中にplotする処理が入っているためprintしなくても表示できる．
sns.heatmap(iris.corr(), vmax=1, vmin=-1, annot=True)

```


![imag3](https://i.imgur.com/Faq8xTe.png)  


これで，相関係数と代表値を計算することができた．ここまでで高校数学のデータの分析が可能となる．さあ，ここまでやってきたデータの可視化からわかることを考察すべし！！



## データ分析の探究（難易度：ふつう）
データ分析の探究では，難易度別に分けてみました．

今回のデータ分析では，あやめというデータセットを使って150サンプルの測定値での分析を行いました．なぜ，あやめのデータを使ったかというと，たくさんの人が使って資料を残してくれているという点です．困った時には調べるとたくさんの情報が出てくるので学習しやすいです．

ということで，探究では，別のデータセットを使って分析をしてみるがよい．というところを持って来ました．では早速探究してみましょう．

### データセット一覧

今回紹介するのは`scikit-learn`のデータセットです．インポートして使っていくわけですが，そもそも何が用意されているのかを確認しましょう．

- Toy datasets（仮想的な）
- Real world datasets

以下のように分かれています

#### Toy datasets

* ボストンの住宅価格
* あやめの種類
* 糖尿病の進行状況
* 手描き文字（数字）
* 生理学的測定結果と運動測定結果
* ワインの種類
* がんの診断結果

#### Real world datasets

* 同一人物のさまざまな状態の顔画像
* トピック別のニュース記事
* トピック別のニュース記事（特徴抽出済み）
* 有名人の顔写真
* 有名人の顔写真（２枚ペア）
* 森林の木の種類
* カテゴリ別のニュース（ベクトル化済み）
* カリフォルニアの住宅価格

この中から気になったデータを`iris`の時のように用意してデータを分析してみよう．その結果から何がわかるのか考察してみよう．

```
分析&考察タイム
```



このように，データセットはたくさんの種類があって，これらのデータがあるから今回のようにデータの分析ができる．そして，次の探究では，予測モデル（AIアルゴリズム）の導入になりますが，そこでもデータのありがたみをより知ることができる．




## データ分析の探究（難易度：おに）

※プログラミングとしては難しいですが，考え方としてはわかってもらいたい（テストの範囲外の可能性ありのため飛ばしても良い）
ここからは2つのテーマで探究を行う．まずは線形解析と非線形解析である．そもそもこの解析は大学統計解析分野における基本的な解析方法で，データの予測アルゴリズムとしてよく利用されている．

### 線形解析

線形解析とは，直線的なデータの関係性をモデル化したもので，ここでは線形回帰のことをいう．イメージとしては一次関数のことで「ある変数（説明変数という）が大きくなると，もう一つの変数（目的変数という）が大きくなるもしくは小さくなる」という関係をモデル化する．

例として，以下を示した．説明変数`x`と目的変数`y`についてこのような関係を定義するとしよう．

|x|y|
|---|---|
|1|2|
|2|4|
|3|6|
|4|8|
|5|10|

この場合，直線系の関係を示すことがわかる．

$y = w _ 0 + w _ 1 x$ （ $y = ax + b$ と同じ）

このモデルでは， $w _ 0$ と $w _ 1$ を求めることで回帰直線を実現できることになる．（ $a$ と $b$ を求めることと同じ ）これを求める方法が分析ごとに異なり，特徴をもつ．ここでは平均二乗法を取り上げる．

#### 平均二乗法

定量分析の一般的な手法で以下の式で示す．

$$ \sum_{k=1}^n \frac{y _ i - (w _ 0 + w _ 1 x _ i)}{n} $$


この式のように，繰り返し同じ処理をしてある値に収束させることを回帰という．

では早速，この回帰モデルを再現していく．

```python
linear_model
興味があれば説明します
coming soon..
```



この平均二乗法を用いた場合のメリットは簡単に予測ができることである．なにしろ直線関数を引くだけでAIが再現できるので，難易度は中学校レベルである．しかし，デメリットがでかい．簡単なデータであれば，直線での予測を行えば良いのだが，複雑なデータを扱う場合は線形だけでは精度が非常にcheapな感じになってしまう．では，この制度を上げるためにはどうすることが良いだろうか．これについて次章で解説する．


### 非線形解析

ここで登場するのは，非線形の考え方である．非線形とは，直線ではなくフリーハンドで線形ではない線（曲線）で平均を絵画していくことである．非線形解析で代表的な解析手法は「クラスタリング（k-means法）」である．ここでは，クラスタリングについて，説明していく．

#### クラスタリングとは．．．

クラスタリングとは，あるデータ群に対して，ランダムでいくつかのグループに分ける．このグループのことをクラスタという．クラスタに分けた後，各クラスタごとに重心をとる．この重心と書くデータの距離を計算して，この距離が少ないクラスタに割り当て直す．新しく設定されたクラスタで再度重心をとる．この重心と書くデータの距離を計算して距離の短いクラスタに割り当て直す．これを，クラスタに変化がなくなるまで繰り返す．こうすることで，直線の平均ではなく，傾向の強いグループごとに平均が取れるので，制度が格段に上がる．ここでのメリットは精度が天地の差であること．デメリットは分類するクラスタによっては精度が上がらないことである．最初のランダムで重心のおおよその位置が決まってしまうので，そこに依存して精度が決まる恐れがある．今回はこのクラスタリングをirisに導入してみる．


では早速，クラスタリングの準備からしていく．

```python
k-means_model
君に時間と余裕があれば説明します（とても長いかつ重たい内容ですのでバーストしない程度にやりましょう）
coming soon..
```



##　データ分析の深いところ

データ分析は近年飽和しつつあるが，これらの分析手法ができてからまだ数年しか経っていない．それほどフレッシュな技術だということであり，情報系の分野は2~3ヶ月でどんどん移り変わっていくものである．そして，どんどん自分で意識を持っていかないと置いてかれる世の中である．ちなみに，今回紹介した分析手法はごく一部であり，他には以下のようなものがある．

- ロジスティック回帰
- ランダムフォレスト
- BART

etc...


興味を持ったらすぐに行動です．自分なりにどんどん探求していってください！！



[参考資料（ほぼ全パターンと言っていいほどの分析手法が掲載されているマジですごいサイト）体験型分析](https://zero2one.jp/ai-word/k-means-method/)  


$ fin.. $






